---
title: "Missing data in R"
author: "Guido Biele"
date: "April 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, fig.align = "center")
sapply(dir("functions",full.names = T), source)
  
```

The goal of this session is to briefly introduce dealing with missing data in R.
We do this by first getting an overview about type of missing data, then moving on to general wise to deal with missing data, and finally looking a a few examples to do analyses in R when data is missing.

Before we get a quick overview about types of missing data, lets clarify why we should worry aboput it. The reasons are:

* missing data can lead to biased effect sizes, i.e. a complete-case analysis can result in estimates that over or underestimate the true effect sizes in the population.
* missing data can lead to inflated variance, i.e. standard errors (and followingly p-values or posterior variances) from a complete-cases analysis are larger than they need to be.

## Types of missing data

Rubin (1976) originally proposed a classification of missing data into three types:

* MCAR or Missing Completely at Random (here, "nomen est omen")
* MAR or Missing At Random (i.e., missing is random conditional on additional observed variables)
* MNAR or Missing Not At Random (is not MCAR or MAR)


One way to better understand these different type so missingness is to use directed acyclical graphs (DAGs) and draw missingness or m-graphs (e.g. Mohan & Pearl, 2018). To explain m-graphs, lets start with a simple example (modified from Mohan & Pearl 2018, who were inspired by Little & Rubin, 2002): We want to investigate the effects of education and age on obesity. A simple 
DAG that represents this relationship looks as follows:

```{r simple_DAG, fig.height=2, fig.width=2,}
library(dagitty)

simple_dag = dagitty("
A 1 @1,0
O O @0,1
E E @-1,0

A O
E O
")
drawdag(simple_dag)
```

This DAG represents the assumption that education (E) and age (A) are causes of obesity (O).


To represent missingness, m-graphs assume a new variable O* that represents the observable variable O after taking the causes for missingness of this variable---R~O~---into account. At the same time, the original variable O becomes a unobserved (latent) variable. Here is such a graph:

```{r MCAR_DAG, fig.height=3, fig.width=3}
mcar_dag = dagitty("
A  1 @1,0
O  U @0,1
E  E @-1,0
O* O @1,2
R_O 1 @2,1

A O
E O
O O*
R_O O*
")
drawdag(mcar_dag)
mtext("MCAR",side = 3,line = -1)
```

This DAG represents a situation with where missingness is completely at random (MCAR). Next, a DAG that described missingness at random (MAR):

```{r MAR_DAG, fig.height=3, fig.width=3}
mar_dag = dagitty("
A  1 @1,0
O  U @0,1
E  A @-1,0
O* O @1,2
R_O 1 @2,1

A O R_O
E O
O O*
R_O O*
")
drawdag(mar_dag)
mtext("MAR",side = 3,line = -1)
```

Here, missingness is random, given that we know education. Finally, we can look at a situation that where missingness is not at random (even taking into account age):

```{r MNAR_DAG, fig.height=3, fig.width=3}
mnar_dag = dagitty("
A  1 @1,0
O  U @0,1
E  E @-1,0
O* O @1,2
R_O 1 @2,1

A O
O R_O
E O
O O*
R_O O*
")
drawdag(mnar_dag)
mtext("MNAR",side = 3,line = -1)
```

Let's compare these three DAGs:

```{r all_DAGs, fig.height=2.5, fig.width=7}
par(mfrow = c(1,3))
drawdag(mcar_dag)
title("MCAR",line = -1)
drawdag(mar_dag)
title("MAR",line = -1)
drawdag(mnar_dag)
title("MNAR",line = -1)
```

A distinction of these types of missingness is important, because they determine if we can still estimate "unbiased" effects and how we need to handle missing data in order to obtain unbiased effects. 

### If the outcome variable is MNAR, it is not possible to obtain unbiased association/effect estimates

In particular, if data are _MNAR_, there is little we can do ^[There are exceptions, see Mohan & Pearl, 2018. To illustrate the problem lets simulate data for the MNAR situation]: 

```{r sim_MNAR, fig.height=4.5, fig.width=6.5}
library(boot)

N = 250
E = rnorm(N)
A = rnorm(N)
O = A - E + rnorm(N) 
R_O = (O+rnorm(N)) > 0

layout(matrix(c(1,0,2,2),nrow = 2),widths = c(1/3,2/3))
drawdag(mnar_dag)

par (mar=c(3,3,0,1), mgp=c(2,.7,0), tck=-.01) 
plot(E,O, pch = 21, bg= R_O, col = (!R_O)+1)
abline(lm(O~E), col = "black", lwd = 2)
abline(lm(O[R_O]~E[R_O]), lwd = 2, lty = 2)
legend("topright",
       pch = c(21,21),
       col = c("black","red"),
       pt.bg = c(1,0),
       legend = c("observed","missing"),
       bty = "n")

```

In this example, we used vectors of data with complete cases as input, which does not show how R automatically delas with missing data. 

### When the data is _MCAR_, simple list-wise deletion (complete case analysis) still provides consistent effect size estimates 

Note though that while listwise deletion gives us an unbiased effect size, we still get inflated standard errors. The following code also shows implicitely that R's default way of dealing with missing data is list-wise/complete case analysis.

```{r MCAR_automatic_listwise_deletion, fig.height=4.5, fig.width=6.5}
my_data = sim_mDAG(mcar_dag, N = N)
head(my_data)

lm_population = lm(O ~ E,my_data)
lm_observed = lm(`O*` ~ E,my_data)

layout(matrix(c(1,0,2,2),nrow = 2),widths = c(1/3,2/3))
drawdag(mcar_dag)

par (mar=c(3,3,0,1), mgp=c(2,.7,0), tck=-.01) 
plot(my_data$E,
     my_data$O,
     pch = 21,
     bg = my_data$R_O,
     col = (!my_data$R_O)+1,
     xlab = "E", ylab = "O")
abline(lm_population, col = "black", lwd = 2)
abline(lm_observed, lwd = 2, lty = 2)
legend("topright",
       pch = c(21,21),
       col = c("black","red"),
       pt.bg = c(1,0),
       legend = c("observed","missing"),
       bty = "n")

summary(lm_population)
summary(lm_observed)

```

The degrees of freedom in the outputs above shows us the difference in cases included in the analysis. The next figure shows regression coefficients and confidence intervals for both analysis. [Also, I wish somebody could remove the ridiculous significance codes!]

```{r MCAR_automatic_listwise_deletion_plot, fig.width=4, fig.height=3}
es = rbind(truth =          get_esci(lm_population)[2,],
           complete_cases = get_esci(lm_observed)[2,])
plot_coefs(es)
```


## Testing assumptions about missingness

The DAGs shown above are important, because they make it (relatively) easy to detect what type of missingness is present in the data. This is relevant because all methods used to deal with missing data build on some assumptions. If these assumptions are violated, our analysis will still produce invalid results, even if it somehow accounts (tries to...) for missingness. Therefor, one should always check if the assumptions hold.

### MCAR vs MAR

One way to check underlying assumptions is to see if the implied conditional indenpendencies hold. We can use the function `impliedConditionalIndependencies` from the [dagitty package](https://cran.r-project.org/web/packages/dagitty/) to see those for the MCAR and MAR cases above (We don't need `dagitty` in this case, but it is useful for more complex DAGs.):

```{r impl_cond_ind}
impliedConditionalIndependencies(mcar_dag)
impliedConditionalIndependencies(mar_dag)
```

Unsurprisingly, the MCAR assumptions implies more independencies. In particular, only the MCAR model assumes that participation (R~O~) is independent of age (A). If we want to test this assumption for our data, we can simply run a regression model `lm(R_o ~ E)` and expect that the coefficient for A is zero. The next few lines of code simulate data from the MCAR and MAR models, each time assuming that the effect size for each path is 0.5, and check the implied conditional independency "A \_||\_ R_O" that holds only for the MCAR model. 

```{r test_impl_cond_ind, fig.height=3, fig.width=7.5}

layout(matrix(c(1,0,2,3,3,3),ncol = 2),
       widths = c(.25,.75),
       heights = c(.45,.1,.45))

data_mar = simulateSEM(mar_dag,
                       b.default = .5)
data_mcar = simulateSEM(mcar_dag,
                        b.default = .5)

fit_mar = lm(R_O ~ A, data_mar)
fit_mcar = lm(R_O ~ A, data_mcar)


drawdag(mcar_dag)
mtext("MCAR",side = 1, line = -1.25,adj = 0)
drawdag(mar_dag)
mtext("MAR", side = 1, line = -1.25,adj = 0)
coefplot2(fit_mcar,
          fit_mar,
          ttl = "R_O ~ A")

```

We see that the regression coefficient for E is not in a region of practical equivalence of +/- .1. Therefor, the assumptions of independence of E and R_O does not hold for the data from the MAR DAG and we cannot simply do a complete case analysis for this data.

### Assessing _equivalence_ is required to evaluate conditional indendence
The use of a region of practical equivalence is rooted in the procedure for [equivalence tests](https://en.wikipedia.org/wiki/Equivalence_test). If we want to show that a regression coeficient is (close to) zero, it is not sufficient to show that it is not significance. Rather, one has to show that the regression coefficient is whith high certainty very small. How small "very small" is should generally be determined by subject matter experts. One possible rule of thumb is that an effect that is only 1/10 of a practically meaningfull effect has practically equivalent with zero. Another rule of thumb could be that such a very small effect should be smaller than the expected effect size of your exposure outcome association ^[i.e. don't say an effect of .05 +/- .02 is practically equivalent with zero when assessing conditional independence, and later call an exposure outcome association of .06 +/- .03 "signicant"]. 
In the application above, I chose an effect size of smaller than 0.1 SMD to be parctically equivalent with 0. Tests for equivalence work by checking if the 90% CIs lie within the ROPE. I you need p-values for this, you can use [equivalence](https://cran.r-project.org/web/packages/equivalence/) the package.

### MAR vs MNAR
We can also check if the assumption of MAR holds. First, lets look at two new examples of a MAR and MNAR situation:

```{r MAR2_MNAR2, fig.height=3, fig.width=6}
mnar2_dag = dagitty("
A 1 @1,0
O U @0,1
E E @-1,0
O* O @1,2
R_O 1 @2,1
M 1 @1,1
M_2 U @1,.5 

A O
O M
M R_O
E O
O O*
R_O O*
O M_2
M_2 R_O
")
mnar2_dag = gsub("O -> M_2","O -> M_2 [beta = 1]", mnar2_dag)


mar2_dag = dagitty("
A  1 @1,0
O  U @0,1
E  E @-1,0
O* O @1,2
R_O 1 @2,1
M 1 @1,1
  
A O
O M
M R_O
E O
O O*
R_O O*
")

par(mfrow = c(1,2))
drawdag(mnar2_dag)
mtext("MNAR2",1,line = -1,adj = 0)
drawdag(mar2_dag)
mtext("MAR2",1,line = -1,adj = 0)

impliedConditionalIndependencies(mnar2_dag)
impliedConditionalIndependencies(mar2_dag)


```

Lets assume that the data were in fact collect in scenario MNAR2, but we hypothesize that we are in scenario MAR2 (because we "have to" assume MAR in order to believe that we can actually deal with missingness). Only when scenario MAR2 is true, is E independent of R~O~ when we adjust for M. So we can test this:

```{r impl_cond_ind2, fig.width=5, fig.height=4}
data_mnar2 = simulateSEM(mnar2_dag,b.default = .5)
lmfit = lm(formula = R_O ~ E + M, data = data_mnar2)
cis = confint(lmfit)
par (mar=c(3,6,1.25,1), mgp=c(2,.7,0), tck=-.01)
plot(0, type = "n",
     ylim = c(.5,3.5),
     xlim = range(cis), 
     yaxt = "n", ylab = "",
     xlab = "standardized beta")
axis(2,at = 1:3, labels = rownames(cis), las = 2)
rect(xleft = -.1,ybottom = 0,xright = .1,ytop = 5,
     col = adjustcolor("green4",alpha = .3), border = NA)
abline(v = 0)
segments(x0 = cis[,1],x1 = cis[,2],y0 = 1:3)
points(coef(lmfit),1:3, pch = 16, cex = 2)
mtext("Model: R_O ~ E + M")
summary(lmfit)
```



## Missingness dependent on a predictor variables is a minor problem

When dealing with missing data, it makes a big difference is missingness is associated with the outcome or predictor variables. If there is only one predictor and missingness depends on the predictor variable listwise deletion is not so problematic ([more here](http://statisticalhorizons.com/listwise-deletion-its-not-evil)). Here is an example DAG:

```{r mnar_predictor, fig.height=3, fig.width=3}
mnarpred_dag = dagitty("
A  1 @1,0
O  U @0,1
E  E @-1,0
O* O @1,2
R_O 1 @2,1
U U @2,0

A O [beta = 1]
E O
R_O O*
A U
U R_O
")

mnarpred_dag = gsub("E -> U","E -> U [beta = 1]", mnarpred_dag)
mnarpred_dag = gsub("U -> R_O","U -> R_O [beta = 1]", mnarpred_dag)
drawdag(mnarpred_dag)

```


And here the results of an analysis of the full data set and the complete cases:
```{r simmnar_predictor, fig.height=4.5, fig.width=4.5}
mnarpred_data = sim_mDAG(mnarpred_dag, N = 400)
tmp = list2env(as.list(mnarpred_data),envir = .GlobalEnv)

par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01) 
plot(E,O, pch = 21, bg= R_O, col = (!R_O)+1)
abline(lm(O~E), col = "black", lwd = 2)
abline(lm(`O*`[R_O]~E[R_O]), col = "black", lwd = 2, lty = 2)
legend("topright",
       pch = c(21,21),
       col = c("black","red"),
       pt.bg = c(1,0),
       legend = c("observed","missing"),
       bty = "n")

```

In the case of only one exposure that also determines missingness, one could hence simply analyse the complete cases ^[Note that using only complete cases would bias the error variance upwards. In contrast, mean imputation would bias error variance downwards]. However, if there a multiple predictors in a model, it can quickly become impractical to delete every case with a missing value in one of the predictor variables.

To summarize this general section about missing data:

* MCAR, MAR, and MNAR are three different types of missingness, each with different consequences for the data analysis
* A good workflow for statistical analysis includes making assumptions about missing data explicit. Missingness graphs using DAGs are useful for this. (one might find out that complete case analysis is OK ^[I guess this is rarely the case] )
* It is good practice to check if the data at hand are consistent with the assumptions made (though, as some might nitpick, a verified assumption is no longer an assumptions).


## Methods to deal with (at least) MAR data


### Don't use ad hoc "methods"

Before we introducing methods to deal with missing data, let's mention what is not really OK: Imputation of missing data with the mean or median of the non-missing data might be convenient, but does not work OK. The next figure illustrates why:


```{r CC_MeanImputation, fig.height=4.5, fig.width=4.5}

my_data$O_mean_imputation = my_data$`O*`
my_data$O_mean_imputation[is.na(my_data$`O*`)] = 
  mean(my_data$O_mean_imputation[!is.na(my_data$`O*`)])

par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01)
plot(my_data$E,
     my_data$`O*`,
     pch = 21, bg = "black")
points(my_data$E[!my_data$R_O],
       my_data$O_mean_imputation[!my_data$R_O],
       pch = 21,
       bg = "orange")
legend("topright",
       pch = 21,
       pt.bg = c("black","orange"),
       legend = c("observed","mean imputed"))
```

One might think that it is the best to just use list-wise deletion (complete case analysis) when the data is MCAR. Indeed, this would not introduce bias. But, as we have seen earlier, throwing away data increases the standard error of parameter estimates. Therefore, it can be useful to not simply do a complete case analysis when data is MCAR.


Some authors give the name _ad hoc techniques_ to methods that somehow deal with missing data, but do not come with a theoretically grounded theory of why they should work. List-wise deletion, pairwise deletion, mean/median/mode imputation, and complete case analysis bepong into this group. We will not look further into these methods.

## Real methods

_All statistical methods to "really" deal with missing data assume that missingness is MAR._ I'm am aware of following ways to substantially deal with missing data:

* Adjustment for predictors of missingness.
* Full information maximum likelihood (FIML). In short, this approach models the joint likelihood of all available data (typically using a multivariate normal distribution) plus parameters of interest like path (or regression) coefficients.
* Expectation maximization (EM). _I know little about this!_
* Multiple imputation (MI). In MI, the analyst uses methods like Multiple Imputation by Chained Equations (MICE) or Hot Deck to generate replicates of the original data set, whereby in each replicate the missing data are replaced with similar but not identical imputed values. The motivation of using multiple replicates is to incorporate uncertainty about the imputed values into the analysis.

A FIML approach is typically used for estimation of structural equation models (SEMs). This works well here, because normally distributed latent variables are central in SEMs, which fits well with the fact that the FIML approach typically involves estimating the multivariate normal distribution for the involved variables. However, when variables in a model are categorical (gender, place of living, ...) the FIML approach is much harder to implement. Indeed, a short google search suggests that there is no plug and play software that reliably implements FIML also for categorical data ([see e.g. here](https://stats.stackexchange.com/questions/51006/full-information-maximum-likelihood-for-missing-data-in-r)). 

So even while some strongly favor FIML ([see e.g. here](https://statisticalhorizons.com/ml-is-better-than-mi)), authoritative reviews tend to point out that MI is better suited to situations where categorical variables are involved.

Here is an example with a linear model. The "trick" is that if missing is predicted by a mediator between "cause" and "effect", we don't want to condition on it. This example also shows that it is advantageous to be able to specify the imputation and "effect" models separately, which works fine with MI (including its Bayesian version), but it not so straight forward for FIML.

### Adjustment for predictors  of participation
This method is not perfect, because it still results in inflated variances of parameter estimates. Still, this method should not be dimissed, because it allows a relatively easy way to obtain consistent estimates, given a specific MAR structure.
For example in this MAR situation introduced above
```{r reshow_MAR_DAG, fig.height=3, fig.width=3}
drawdag(mar_dag)
mtext("MAR",side = 3,line = -1)
```

we can obtain an unbiased estimate by simply adjusting for A.

```{r adjust4MAR, fig.width=4, fig.height=3}
my_data = sim_mDAG(mar_dag, N = 250)

lm_population = lm(O ~E, my_data)
lm_cc_adjusted = lm(`O*` ~ E + A, my_data)

es = rbind(truth =                   get_esci(lm_population)[2,],
           complete_cases_adjusted = get_esci(lm_cc_adjusted)[2,])

plot_coefs(es)
```

As expected, the standard error for the adjusted model based on complete data is largers (less data, more predictors).


### FIML regression in R with lavaan.

In the previous MAR scenario we could simply condition on A to remove bias. However, this is not possible if the predictor of missingness is also a mediator between the exposure and the outcome. The next figure shows and example:

```{r MAR_mediator_dag, fig.height=3, fig.width=3}
mar_mediator_dag = dagitty("
M  1 @1,0
O  U @0,1
E  1 @-1,0
O* O @1,2
R_O 1 @2,1
  
M O R_O
E O M
O O*
R_O O*
")

mnarpred_dag = gsub("E -> M","E -> M [beta = 1]", mnarpred_dag)
mnarpred_dag = gsub("M -> R_O","M -> R_O [beta = 1]", mnarpred_dag)
drawdag(mar_mediator_dag)

```

Here, we can use the [lavaan](https://cran.rstudio.com/web/packages/lavaan/index.html) packagem which was (and is) developed to fit SEM model in R. However, it can also be used to fit _linear_ FIML regression. Lets first look at the true association and association from futile methods to deal with missing data:

```{r wrong_regressions_mar, fig.width=4, fig.height=3}
my_data = sim_mDAG(mar_mediator_dag,
                   seed = 11)


es = rbind(truth =              get_esci(lm(O ~ E, my_data))[2,],
           complete_cases =     get_esci(lm(`O*` ~ E, my_data))[2,],
           complete_cases_adj = get_esci(lm(`O*` ~ E + M, my_data))[2,])

plot_coefs(es)
```



The correct total effect of E on O is `r round(es[1,1],digits = 2)`. To recover this, we fit a FIML regression that models the effect of E and O and, importantly, the covariances for E, O, and M:

```{r FIML_regression, fig.width=4, fig.height=3}
library(lavaan)

model <- '
# regression model 
Ox ~ E

# co-variances
Ox ~~ M
E ~~ M
'

my_data$Ox = my_data$`O*`
FIML_fit <- sem(model, my_data,
           missing='fiml',
           meanstructure=TRUE, 
           fixed.x=FALSE)
summary(FIML_fit)

es_FIML = parameterEstimates(FIML_fit)[1,c("est","ci.lower","ci.upper")]
colnames(es) = names(es_FIML)
es = rbind(es, es_FIML)
rownames(es)[4] = "FIML"

plot_coefs(es,
           clrs = c("green4","black","black","orange"))
```

Even if the FIML is not perfect, it is better than the complete case analysis. [With more time, one should add some simulations to show that the FIML approach is unbiased and the complete case approach not. Same for all other methods]

### Multiple Imputation by Chained Equations with the mice package

An alternative to the FIML approach is to use multiple imputation by chained equation. The most popular r packeg to implement this is [mice](https://cran.rstudio.com/web/packages/mice/index.html). Some people seem to have [strong opinions about FIML vs multiple imputations](https://statisticalhorizons.com/ml-better-than-mi). A fair summary seems to be that
* FIML is preferred when missingness does not dependt on auxiliary variables, the association between the involved variables is well described by a multivariate normal distribution, and there are no strong non-linearities (in the associations between variables)
* MI is preferred when the imputation model has many variables not needed in the effect model, variables are not continuous, and interaction effects are important

One good reason to use `mice` is the extensice documentation. Among other things there is an online [book](https://stefvanbuuren.name/fimd/) with lots of usefull explanations and example code also for nore advances analyses, and a set of [vignettes](https://www.gerkovink.com/miceVignettes/) that serve as a moderately long introduction.

As a simple introduction to an analysis with mice, we analyse the MAR data det we just analysed with FIML. We start by generating multiple impuations of our data set:

```{r mice_imputation}
library(mice)

my_imputed_data = mice(
  my_data[,c("Ox","E","M")], # data with missing values
  m = 5,                     # number of imputed data sets
  maxit=25,                  # number of iterations in a chain
  meth='pmm',                # imputation method
  seed=500,
  printFlag = F)
```

Before we use the data, we should check the imputation worked. One way to do this is to show densities and scatter plots with observed and imputed data in different colors.

```{r mice_plots, fig.width=4, fig.height=3}
par(mfrow = c(2,2))
densityplot(my_imputed_data)
xyplot(my_imputed_data,Ox ~ E)
xyplot(my_imputed_data,Ox ~ M)
```

Note that the lower mean for the impueted data is expected, because our data generateing model specified that cases with low exposure values were more likely to miss the outcome variable.


Five imputations were OK for visualization purposes, but we need more for the real analysis.

```{r mice_imputationb}
my_imputed_data = mice(
  my_data[,c("Ox","E","M")], # data with missing values
  m = 100,                    # number of imputed data sets
  maxit=50,                  # number of iterations in a chain
  seed=500,
  printFlag = F)
```


Now we can also better visualize what the _multipel_ means in multiple imputation. one missing value receives in each imputed data set a different value:

```{r mice_imputations_compare1, fig.width=8, fig.height=6}
idx_missing = which(!my_data$R_O)
par(mfrow = c(5,5), mar = c(2,.5,.5,.5),mgp=c(2,.7,0), tck=-.01)
for (k in 1:25) {
  hist(t(my_imputed_data$imp$Ox[k,]),
       xlab = "",
       ylab = "",
       bty = "n",
       yaxt = "n",
       main = "")
  abline(v = my_data$O[idx_missing[k]], col = "green4", lwd = 2)
}
```

```{r mice_imputations_compare2, fig.width=4, fig.height=4}
par(mfrow = c(1,1),mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01)
plot(my_data$O[idx_missing],
     rowMeans(my_imputed_data$imp$Ox),
     xlab = "truth",
     ylab = "imputed")
```

Now that we have checked the results of the imputation, we run the analysis with all imputed data sets:

```{r mice_analysis}
MI_fit = with(my_imputed_data,
              lm(Ox ~ E))
```

The object MI_fit is of the class [mira](https://stefvanbuuren.name/mice/reference/mira-class.html), and contains in slote 4 for each imputed data set the result of the regression model we specified. We can look at all coeffcients:

```{r mice_summary}
summary(MI_fit)
```

And we can look at the pooled the results:

```{r mice_pooled_summary, fig.width=4, fig.height=3}
s = summary(pool(MI_fit), conf.int = T)
s[,1:5]

es_MI = s[2,c("estimate","2.5 %","97.5 %")]
names(es_MI) = names(es)
es = rbind(es, es_MI)
rownames(es)[5] = "MI"

plot_coefs(es,
           clrs = c("green4","black","black","orange","blue"))


```

### Missing data and non-linear effects
In the previous example, MI and FIML lead more or less to the same results, because the involved variables are in fact multivariate normal and no interaction effects were present. In the final example we shall investigate such and example. The following situation is the same as above, except that we have an additional variable L for county (fylke). The idea is that the outcome obesity and participation could depend on where one lives.

```{r mar_interaction_dag, fig.height=3, fig.width=3}
mar_interaction_dag = dagitty("
M  1 @1,0
O  U @0,1
E  1 @-1,0
O* O @1,2
R_O 1 @2,1
L 1 @1,1
  
M O R_O
E O M
O O*
R_O O*
L O R_O
")
drawdag(mar_interaction_dag)
```

In all previous analyses we could use dagitties simulateSEM function to generate data from a DAG, because we treated data as multivariate normal. However, we can't do this now, because

* L is a categorical variables and
* the effect of L on O is assumed to be that of an effect modifier.

The followig code generates data from this model:

```{r mar_interaction_sim}
N = 500
# we start with the exogeneous variables:
E = rnorm(N)
# now the endogenous variables
M = E + rnorm(N)
# cases come from 5 counties
L = cut(runif(N), 
        breaks = seq(-.001,1.001,length = 6),
        labels = paste0("L",1:5),
        ordered_result = T)
# O depends on M and E, whereby the effect of E depends on L
O = M - E * scale(as.numeric(L))*2 + rnorm(N)
# R_O depends on M plus a non-linear effect of C
R_O = M + poly(as.numeric(L),2) %*% c(20,20) + rnorm(N)
R_O = R_O > 0
# now we can define the observed data
`O*` = O
`O*`[!R_O] = NA
Ox = `O*`

mar_interaction_data = data.frame(E = E, M = M,
                                  O = O, L = L, R_O = R_O,
                                  `O*` = `O*`, Ox = Ox) 
```

Now we can look at the association between E and O, stratified by participation.

```{r plot_interaction_sim, fig.height=4.5, fig.width=4.5}
par (mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01)
bg = sapply(R_O,
            function(x)
              ifelse(x == T,
                     "black",
                     "white"))
plot(E,O, pch = 21, bg=adjustcolor(bg,alpha = .5), col = (!R_O)+1)
abline(lm(O~E), col = "black", lwd = 2)
abline(lm(`O*`[R_O]~E[R_O]), col = "black", lwd = 2, lty = 2)
legend("bottomright",
       pch = c(21,21),
       col = c("black","red"),
       pt.bg = c(1,0),
       legend = c("observed","missing"),
       bty = "n")

```

Obviously, we would get a biased estimate when using only complete cases. We also can't adjust for M, becasue M is a mediator. So lets try FIML:

```{r FIMLi_fit, eval = F}
mar_interaction_data$Ln = scale(as.numeric(mar_interaction_data$L))
model <- '
# regression model 
Ox ~ E

# co-variances
Ox ~~ M
E ~~ M
Ox ~~ Ln
E ~~ Ln
M ~~ Ln
'

FIMLi_fit <- sem(model,
                mar_interaction_data,
                missing='fiml',
                meanstructure=TRUE, 
                fixed.x=FALSE)
summary(FIMLi_fit)

```

Note that here we transformed the ordinal variabl L to a numer variable, because lavaan cannot deal with categorical variables when doing FIML estimation (Mplus can). Still, the result are off, because we haven't added informatio about the interaction to the model. The next model does this.

```{r FIMLi_fit_workaround}
mar_interaction_data$iEL = scale(as.numeric(mar_interaction_data$L)) * E

model <- '
# regression model 
Ox ~ E

# co-variances
Ox ~~ M
E ~~ M
Ox ~~ iEL
E ~~ iEL
M ~~ iEL
'

FIMLi_fit <- sem(model,
                mar_interaction_data,
                missing='fiml',
                meanstructure=TRUE, 
                fixed.x=FALSE)
summary(FIMLi_fit)

```

Indeed, the result look nice. This result drives again home that it important to have a good idea about the data generating hypothesis, when doing imputation.

Now lets try multiple imputation. To make things more realistic, we add a bit more missing data (completely random).

```{r mice2, fig.width=5, fig.height=3}
library(VIM)
idata = mar_interaction_data[,c("E","M","L","Ox","R_O")]
#for (v in 1:3)
#  idata[sample(N,N*.1),v] = NA

aggr_plot = aggr(idata,
                 col=c('green4','red'),
                 numbers=TRUE,
                 sortVars=TRUE,
                 labels=names(data),
                 cex.axis=.7,
                 gap=3,
                 ylab=c("Histogram of missing data",
                        "Pattern"))
```


The basic command to impute data is stil simple:

```{r impute_mice2}

my_imputed_data2 = mice(
  idata, # data with missing values
  m = 3,                     # number of imputed data sets
  maxit=25,                  # number of iterations in a chain
  seed=500,
  printFlag = F)

```

Before we look at the results, lets check who mice did the imputations. 

```{r mice_imputation_models}
my_imputed_data2$method
my_imputed_data2$predictorMatrix
my_imputed_data2$formulas
```

Lets see if the results look reasonable by looking at density and scatter plots.

```{r impute_mice2_plots, fig.width=5, fig.height=3}
densityplot(my_imputed_data2)
xyplot(my_imputed_data2,
       Ox ~ E | L,
       type = c("p", "smooth"))
```


Definitively not great, rather horrible. The mian reason is that model does not take into account interaction terms. `mice` uses the concept of _passive imputation_ to insure that derived variables (like interactions) are consistent with imputations throughout the imputation process. Detailed information about specifyingh such more complex imputation models can be found [here](https://stefvanbuuren.name/fimd/sec-knowledge.html), including a section about [efficient imputations of sum-scores](https://stefvanbuuren.name/fimd/sec-knowledge.html#sec:sumscores). To set up passive imputation of an interaction variable one has to:

* intitalize hat variable
* specify a method for that variable, i.e. define an R expression that tell mice how to generate the derived variable
* adjust the prediction matrix to make sure the derived variable is only used as a predictor where needed


In addition we also add a variable that codes if Ox was missing as a predictor (a trick from the [mi package](https://cran.rstudio.com/web/packages/mi/)).
```{r mice2_add_method}
idata$iEL = as.vector(idata$E * scale(as.numeric(idata$L)))
method = make.method(idata)

expr = expression(scale(as.numeric(L)) * E)
method["iEL"] = paste("~I(", expr, ")", sep = "")
method["R_O"] = "logreg"

pred = make.predictorMatrix(idata)
pred[c("E","L","M","Ox"),"iEL"] = 0
pred["Ox","iEL"] = 1
pred["Ox",c("E","L")] = 0
pred
```

Now we have defined the interaction predictor and added a method of how to contruct it from existing variables (We have also specified that L predicts only R_O and Ox. [^ We could also specify that O is predicted only by E, but because we are only interested in prediction here, and not regression coefficients, it is OK to keep M in]). Next, we use this method for the imputations.

```{r mice2_impute}
imp <- mice(idata,
            meth = method,    # method for passive imputation
            pred = pred,      # matrix of predictors for all variables
            m = 3,            # number of imputed data sets
            maxit=250,         # number of iterations in a chain
            seed=500,
            printFlag = F)

```

Now that we have a model that is a bit more complex we go through more "checking" steps. MICE is a montecarlo algorithm, so we need to check convergence. We do this by plotting how parameters change over time (there are more sophisticated ways to do this, like comparing within and betweeen chain variance, but MICE does not support those.)

```{r mice_convergence, fig.width=5, fig.height=3}
plot(imp)
```

And we use strip plots to check if all variables have plausible values (i.e. they are nor outside the range of the observed values)

```{r mice_stripplot, fig.width=5, fig.height=3}
stripplot(imp)
```

Density plots do a similar job.
```{r mice2_plot1, fig.width=3, fig.height=3}
densityplot(imp)
```

Particularily interesting are the associations between O/Ox and E given L. We first look at the complete data and then at the imputed data.

```{r mice2_plot2, fig.width=5, fig.height=3}
xyplot(imp,
       Ox ~ E | L,
       type = c("p", "smooth"))
xyplot(O ~ E | L,
       mar_interaction_data,
       type = c("p", "smooth"),
       index.cond=list(c(1:5)))
```

While the imputation was not perfect (thre is a problem with L1) we see that we have filled in lost of cases for groups L1-L3, where the correlation is typically positive. A complete cases analysis without these imputed data points naturally underestimates the association between E and O. Still, before we move on, lets see if we can improbe the imputation by using a different imputation method than predcitive mean matching (pmm) for Ox.

```{r mice_Ox_norm_imputation, fig.width=5, fig.height=3}
method["Ox"] = "norm"
imp <- mice(idata,
            meth = method,    # method for passive imputation
            pred = pred,      # matrix of predictors for all variables
            m = 3,            # number of imputed data sets
            maxit=250,         # number of iterations in a chain
            seed=500,
            printFlag = F)
xyplot(imp,
       Ox ~ E | L,
       type = c("p", "smooth"))

```

OK, this looks much better. The problem with predictive mean matching is, that it will not allow more expreme values than the observed ones. However, for the data generating process we are looking at, the most extreme values were missing. If this is a possibility, pmm is not the best imputation method.

Now we re-do the imputation to generate more data sets and then run the analysis.

```{r}
imp <- mice(idata,
            meth = method,    # method for passive imputation
            pred = pred,      # matrix of predictors for all variables
            m = 25,           # number of imputed data sets
            maxit=50,         # number of iterations in a chain
            seed=500,
            printFlag = F)

MI_fit2 = with(imp,
              lm(Ox ~ E))
summary(pool(MI_fit2), conf.int = T)
```

make last coefplot

So FIML and MI both generate usful results, as long as one is careful in specifying a correct model. This reinforces that careful exploration of the data and considerate use of an imputation model are curcial for successful imputation.

## Summary

## Resources
* A general introduction on [how R handles missing data](https://stats.idre.ucla.edu/r/faq/how-does-r-handle-missing-values/)
* R [task view](https://cran.r-project.org/web/views/MissingData.html) about missing data
* Stef van Buren's (author of `mice`) [book](about multiple imputations)
* [Vignettes](https://www.gerkovink.com/miceVignettes/) for using `mice` 
* Bayesian [joint estimation of imputation and effect model](https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html) with brms